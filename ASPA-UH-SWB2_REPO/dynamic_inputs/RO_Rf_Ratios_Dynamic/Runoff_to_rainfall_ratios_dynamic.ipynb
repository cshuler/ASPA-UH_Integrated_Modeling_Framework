{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       " <style>\n",
       "    div#notebook-container    { width: 95%; }\n",
       "    div#menubar-container     { width: 85%; }\n",
       "    div#maintoolbar-container { width: 99%; } </style> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import arcpy\n",
    "from arcpy.sa import *\n",
    "\n",
    "# make the screen bigger!\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(data=\"\"\" <style>\n",
    "    div#notebook-container    { width: 95%; }\n",
    "    div#menubar-container     { width: 85%; }\n",
    "    div#maintoolbar-container { width: 99%; } </style> \"\"\"))\n",
    "\n",
    "arcpy.env.overwriteOutput = True # make sure overwrite files is on\n",
    "\n",
    "pd.options.display.float_format = '{:.3f}'.format  # MAKE DAtaframe not display scientific notation\n",
    "\n",
    "homedir = os.getcwd()\n",
    "workspace = os.path.join(homedir, 'Workspace')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile Rainfall amounts for each watershed that has a stream gauge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "measured_watersheds = os.path.join(homedir, 'Data', 'Measured_watersheds.shp')\n",
    "\n",
    "\n",
    "mo_list = [\"01\", \"02\", \"03\",\"04\", \"05\", \"06\",\"07\", \"08\", \"09\",\"10\", \"11\", \"12\"]\n",
    "mo_days = [31, 28 , 31, 30, 31, 30, 31, 31, 30, 31, 30, 31]\n",
    "precp_dict = {}\n",
    "\n",
    "for idx, i in enumerate(mo_list):\n",
    "\n",
    "# run the zonal stats on the raster for each watershed and export as a table ZonalStatisticsAsTable (in_zone_data, zone_field, in_value_raster, out_table, {ignore_nodata}, {statistics_type})\n",
    "    temp_raster = os.path.join(homedir, 'Data', 'Gridded_rain', 'PRISM_ppt_tutuila_30yr_normal_80mM1_{}_asc.asc'.format(i))\n",
    "\n",
    "\n",
    "    # using measured watershed areas, calculate the total sum amount of water that precipitates in a given month in each wathershed area, save to table \n",
    "    outZSaT = ZonalStatisticsAsTable(measured_watersheds,  \"Zone_ID\",  temp_raster,  os.path.join(workspace, 'dumb_table.dbf'), \"DATA\")\n",
    "    # make the table useful as opposed to arc dumb format\n",
    "    arcpy.TableToTable_conversion(outZSaT, workspace, 'Zonal_stats_precip_mon_.csv')\n",
    "    arcpy.Delete_management(os.path.join(workspace,'dumb_table.dbf'))  \n",
    "\n",
    "    # each table needs some reformatting to get volumetric water amounts \n",
    "    data = pd.read_csv(os.path.join(workspace, 'Zonal_stats_precip_mon_.csv'))    # read into pandas dtaframe\n",
    "    data['ave_precip_in_m'] = (data['MEAN']/100000)                                # data units are in mm*100, convert to m\n",
    "\n",
    "    # need to read in the shapefile of measured watersheds to get the areas to calculate volumetirc amounts of water\n",
    "    arr = arcpy.da.TableToNumPyArray(measured_watersheds, (\"Zone_ID\", 'area_m2'))   # read shapefile into an array\n",
    "    arcistheworst = list(zip(*arr))                                                 # why would you make your arrays out of tuples? \n",
    "    dataset = pd.DataFrame({'Zone_ID':arcistheworst[0],'area_m2':arcistheworst[1]}) # convert dumb tuple array to pandas dataframe of areas\n",
    "\n",
    "    data = data.merge(dataset, how='outer', on='Zone_ID')  # add areas to the dataframe\n",
    "    data['precip_vol_m3pmonth'] = data['ave_precip_in_m']*data['area_m2']    # get it into volumne per month\n",
    "    data['precip_vol_m3pd'] = data['precip_vol_m3pmonth']/mo_days[idx]   # get it into volumne per month\n",
    "\n",
    "    \n",
    "    pert_frame = data[['Zone_ID', 'precip_vol_m3pd']]\n",
    "    precp_dict[\"month_{}\".format(i)] = pert_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format the rainfall and runoff data into runoff to rainfall ratios for measured watersheds\n",
    "- raw monthly consolidated runoff from ASPA-UH_Integrated_Modeling_Framework/ASPA-UH_Stream_REPO/Run/UH_ASPA_Streamflow_process_w_USGS.ipynb \n",
    "- raw precip data from precp_dict in this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "Raw_RO_data_path = os.path.join(\"..\", \"..\", \"..\", \"ASPA-UH_Stream_REPO\", \"workspace\", \"Raw_RO_data_Measured.csv\")\n",
    "\n",
    "# format the precipitation data into zones as columns\n",
    "precip_frame = pd.DataFrame(columns= [47, 48, 63, 73, 85, 118, 125, 133, 163, 168, 236, 241, 272, 307, 342])\n",
    "\n",
    "for i in precp_dict:\n",
    "    tempframe = precp_dict[i].set_index('Zone_ID').transpose()\n",
    "    tempframe['month'] = i\n",
    "    tempframe = tempframe.set_index('month')\n",
    "    precip_frame = precip_frame.append(tempframe)\n",
    "    \n",
    "# format the streamflow datasheet \n",
    "RO_raw = pd.read_csv(Raw_RO_data_path)              \n",
    "RO_raw = RO_raw.set_index('Zone_ID')\n",
    "del RO_raw['Site']\n",
    "RO_raw = RO_raw.sort_index()\n",
    "\n",
    "# pull it apart and atranspose it\n",
    "RO_frame  = pd.DataFrame(columns = [], data = [])\n",
    "for row in RO_raw.iterrows():\n",
    "    temp_frame = pd.DataFrame(columns = [row[0]], data = row[1])\n",
    "    RO_frame = RO_frame.join(temp_frame, on=None, how='outer') \n",
    "    \n",
    "# make the index exactly match the precip dataset for the division\n",
    "RO_frame = RO_frame.reset_index()\n",
    "RO_frame['month_idx'] = RO_frame['index'].apply(lambda x: str(x.split(\"_\")[0])+\"_\"+str(x.split(\"_\")[1]))\n",
    "RO_frame = RO_frame.set_index('month_idx')\n",
    "del RO_frame['index']\n",
    "\n",
    "#calculate the runoff to rainfall ratios\n",
    "RO_to_RF_Ratios = RO_frame.divide(precip_frame, axis='rows')\n",
    "\n",
    "\n",
    "\"\"\"Due to the short dataset, some of these ratios are outside the boundaries of what is reasonable. Reasonable is here defined by the recorded runoff to rainfall rations by Perault 2010, using USGS data, \n",
    "Therefore if the  calculated rations are <16% or are >54% then set them equal to those from Izuka and perault which were = 0.307 for west and 0.255 for east and the average of this is 0.281 \"\"\"\n",
    "for y in ydim:\n",
    "    for x in xdim:\n",
    "        if RO_to_RF_Ratios.iloc[y,x] > 0.54:\n",
    "            RO_to_RF_Ratios.iloc[y,x] = 0.281\n",
    "            \n",
    "        if RO_to_RF_Ratios.iloc[y,x] < 0.16:\n",
    "            RO_to_RF_Ratios.iloc[y,x] = 0.281\n",
    "            \n",
    "        if ~np.isfinite(RO_to_RF_Ratios.iloc[y,x]):\n",
    "            RO_to_RF_Ratios.iloc[y,x] = 0.281\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This cell interpolates RO:RF ratios from measured watersheds to ungauged watersheds based on proximity and creates an output dataset for SWB2\n",
    "Proximity was manually determined based on manual assignemt from examination of a map. \n",
    "\n",
    "Alos note that Tafuna - Leone RO:RF ratios are different based on the MFR effect (see documentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "All_RoRf_ratios = pd.DataFrame(index = RO_to_RF_Ratios.index)   # create empty dataframe\n",
    "All_RoRf_ratios[\"1\"] =RO_to_RF_Ratios[[118, 133]].mean(axis=1)\n",
    "All_RoRf_ratios[\"2\"] =RO_to_RF_Ratios[[236, 133]].mean(axis=1)\n",
    "All_RoRf_ratios[\"3\"] =RO_to_RF_Ratios[[307, 342]].mean(axis=1)\n",
    "All_RoRf_ratios[\"4\"] =RO_to_RF_Ratios[[307]].mean(axis=1)\n",
    "All_RoRf_ratios[\"5\"] =RO_to_RF_Ratios[[236, 307]].mean(axis=1)\n",
    "All_RoRf_ratios[\"6\"] =RO_to_RF_Ratios[[272]].mean(axis=1)\n",
    "All_RoRf_ratios[\"7\"] =RO_to_RF_Ratios[[307]].mean(axis=1)\n",
    "All_RoRf_ratios[\"8\"] =RO_to_RF_Ratios[[342]].mean(axis=1)\n",
    "All_RoRf_ratios[\"9\"] =RO_to_RF_Ratios[[272, 342]].mean(axis=1)\n",
    "All_RoRf_ratios[\"10\"] =RO_to_RF_Ratios[[133, 241]].mean(axis=1)\n",
    "All_RoRf_ratios[\"11\"] =RO_to_RF_Ratios[[47, 63]].mean(axis=1)\n",
    "All_RoRf_ratios[\"12\"] =RO_to_RF_Ratios[[73, 85, 47]].mean(axis=1)\n",
    "All_RoRf_ratios[\"13\"] =RO_to_RF_Ratios[[47]].mean(axis=1)\n",
    "All_RoRf_ratios[\"14\"] =RO_to_RF_Ratios[[47, 48]].mean(axis=1)\n",
    "All_RoRf_ratios[\"15\"] = 0.065    # note this is tafuna Leone with special runoff properties\n",
    "All_RoRf_ratios[\"16\"] =RO_to_RF_Ratios[[47, 48]].mean(axis=1)\n",
    "All_RoRf_ratios[\"17\"] =RO_to_RF_Ratios[[47, 48]].mean(axis=1)\n",
    "All_RoRf_ratios[\"18\"] = 0.065\n",
    "All_RoRf_ratios[\"19\"] = 0.065\n",
    "All_RoRf_ratios[\"20\"] =RO_to_RF_Ratios[47]\n",
    "All_RoRf_ratios[\"21\"] =RO_to_RF_Ratios[63]\n",
    "All_RoRf_ratios[\"22\"] =RO_to_RF_Ratios[73]\n",
    "All_RoRf_ratios[\"23\"] =RO_to_RF_Ratios[85]\n",
    "All_RoRf_ratios[\"24\"] =RO_to_RF_Ratios[118]\n",
    "All_RoRf_ratios[\"25\"] =RO_to_RF_Ratios[125]\n",
    "All_RoRf_ratios[\"26\"] =RO_to_RF_Ratios[133]\n",
    "All_RoRf_ratios[\"27\"] =RO_to_RF_Ratios[163]\n",
    "All_RoRf_ratios[\"28\"] =RO_to_RF_Ratios[168]\n",
    "All_RoRf_ratios[\"29\"] =RO_to_RF_Ratios[236]\n",
    "All_RoRf_ratios[\"30\"] =RO_to_RF_Ratios[241]\n",
    "All_RoRf_ratios[\"31\"] =RO_to_RF_Ratios[272]\n",
    "All_RoRf_ratios[\"32\"] =RO_to_RF_Ratios[307]\n",
    "All_RoRf_ratios[\"33\"] =RO_to_RF_Ratios[342]\n",
    "\n",
    "# create a date column for the desired years of the simualtion \n",
    "date_col = []\n",
    "for year in range(2000,2012):\n",
    "    for month in range(1,13):\n",
    "        Date = \"{}/1/{}\".format(month, year)\n",
    "        date_col.append(Date)\n",
    "date_col_frame = pd.DataFrame(index = date_col)\n",
    "\n",
    "# make a repeating dataframe of the RoRF values\n",
    "two =    pd.concat([All_RoRf_ratios, All_RoRf_ratios])\n",
    "four =   pd.concat([two, two])\n",
    "eight =  pd.concat([four, four])\n",
    "twelve = pd.concat([eight, four])\n",
    "twelve[\"Date\"] =  date_col          # merge on date column to the data\n",
    "\n",
    "# print out a copy of the RO-RF data to be ingested into SWB2\n",
    "RO_Rf_ratios_Dynamic_monthly_2000_2011 = twelve.set_index('Date')\n",
    "RO_Rf_ratios_Dynamic_monthly_2000_2011.to_csv(os.path.join(\".\", 'RO_Rf_ratios_Dynamic_monthly_2000_2011.txt'), header=True, index=True, sep='\\t', mode='a', float_format = \"%.5f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
